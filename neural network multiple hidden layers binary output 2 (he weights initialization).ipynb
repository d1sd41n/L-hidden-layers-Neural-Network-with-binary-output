{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "#from dnn_app_utils_v3 import *\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) *np.sqrt(2./layers_dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = W.dot(A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization. (≈ 1 line of code)\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 105\n",
      "Number of testing examples: m_test = 45\n",
      "number of features of each example: num_n = 4\n",
      "shape of x_train: (105, 4)\n",
      "shape of y_train: (105, 1)\n",
      "shape of x_test: (45, 4)\n",
      "shape of y_test: (45, 1)\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "# Iris dataset\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = ((iris.target != 0) * 1)  # convert the target's dataset into binary\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3)\n",
    "\n",
    "m_train = len(x_train)\n",
    "m_test = len(x_test)\n",
    "num_n = x_train.shape[1]\n",
    "numtest_n = x_test.shape[1]\n",
    "\n",
    "y_train = y_train.reshape(m_train,1)\n",
    "y_test = y_test.reshape(m_test,1)\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"number of features of each example: num_n = \" + str(num_n))\n",
    "print(\"shape of x_train:\",x_train.shape)\n",
    "print(\"shape of y_train:\",y_train.shape)\n",
    "print(\"shape of x_test:\",x_test.shape)\n",
    "print(\"shape of y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "### CONSTANTS ###\n",
    "layers_dims = [x_train.shape[1], 5, 1] #  4-layer model\n",
    "print(layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.099293\n",
      "Cost after iteration 100: 0.095154\n",
      "Cost after iteration 200: 0.091316\n",
      "Cost after iteration 300: 0.087738\n",
      "Cost after iteration 400: 0.084390\n",
      "Cost after iteration 500: 0.081251\n",
      "Cost after iteration 600: 0.078434\n",
      "Cost after iteration 700: 0.075947\n",
      "Cost after iteration 800: 0.073602\n",
      "Cost after iteration 900: 0.071380\n",
      "Cost after iteration 1000: 0.069276\n",
      "Cost after iteration 1100: 0.067330\n",
      "Cost after iteration 1200: 0.065480\n",
      "Cost after iteration 1300: 0.063767\n",
      "Cost after iteration 1400: 0.062179\n",
      "Cost after iteration 1500: 0.060637\n",
      "Cost after iteration 1600: 0.059160\n",
      "Cost after iteration 1700: 0.057748\n",
      "Cost after iteration 1800: 0.056415\n",
      "Cost after iteration 1900: 0.055136\n",
      "Cost after iteration 2000: 0.053909\n",
      "Cost after iteration 2100: 0.052731\n",
      "Cost after iteration 2200: 0.051598\n",
      "Cost after iteration 2300: 0.050508\n",
      "Cost after iteration 2400: 0.049474\n",
      "Cost after iteration 2500: 0.048482\n",
      "Cost after iteration 2600: 0.047525\n",
      "Cost after iteration 2700: 0.046619\n",
      "Cost after iteration 2800: 0.045756\n",
      "Cost after iteration 2900: 0.044925\n",
      "Cost after iteration 3000: 0.044126\n",
      "Cost after iteration 3100: 0.043357\n",
      "Cost after iteration 3200: 0.042619\n",
      "Cost after iteration 3300: 0.041903\n",
      "Cost after iteration 3400: 0.041209\n",
      "Cost after iteration 3500: 0.040535\n",
      "Cost after iteration 3600: 0.039882\n",
      "Cost after iteration 3700: 0.039246\n",
      "Cost after iteration 3800: 0.038629\n",
      "Cost after iteration 3900: 0.038035\n",
      "Cost after iteration 4000: 0.037458\n",
      "Cost after iteration 4100: 0.036897\n",
      "Cost after iteration 4200: 0.036352\n",
      "Cost after iteration 4300: 0.035822\n",
      "Cost after iteration 4400: 0.035306\n",
      "Cost after iteration 4500: 0.034804\n",
      "Cost after iteration 4600: 0.034314\n",
      "Cost after iteration 4700: 0.033837\n",
      "Cost after iteration 4800: 0.033371\n",
      "Cost after iteration 4900: 0.032917\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(x_train.T, y_train.T, layers_dims = layers_dims, learning_rate = 0.0005,num_iterations = 5000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(x_train.T, y_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(x_test.T, y_test.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 890\n",
      "number of features of each example: num_n = 4\n",
      "shape of x_train: (890, 17)\n",
      "shape of y_train: (890, 1)\n",
      "shape of x_test: (417, 17)\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "# Titanic Dataset\n",
    "\n",
    "X_train = pd.read_csv('./dataset/X_train.csv')\n",
    "y_train = pd.read_csv('./dataset/y_train.csv')\n",
    "X_test = pd.read_csv('./dataset/X_test.csv')\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "m_train = len(X_train)\n",
    "m_test = len(X_test)\n",
    "num_n = x_train.shape[1]\n",
    "numtest_n = x_test.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"number of features of each example: num_n = \" + str(num_n))\n",
    "print(\"shape of x_train:\",X_train.shape)\n",
    "print(\"shape of y_train:\",y_train.shape)\n",
    "print(\"shape of x_test:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 100, 50, 25, 10, 1]\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [17, 100, 50, 25, 10, 1]\n",
    "print(layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.801868\n",
      "Cost after iteration 100: 0.410970\n",
      "Cost after iteration 200: 0.386790\n",
      "Cost after iteration 300: 0.377157\n",
      "Cost after iteration 400: 0.369899\n",
      "Cost after iteration 500: 0.363562\n",
      "Cost after iteration 600: 0.358638\n",
      "Cost after iteration 700: 0.354491\n",
      "Cost after iteration 800: 0.351350\n",
      "Cost after iteration 900: 0.349114\n",
      "Cost after iteration 1000: 0.350270\n",
      "Cost after iteration 1100: 0.347789\n",
      "Cost after iteration 1200: 0.346440\n",
      "Cost after iteration 1300: 0.347368\n",
      "Cost after iteration 1400: 0.340295\n",
      "Cost after iteration 1500: 0.339313\n",
      "Cost after iteration 1600: 0.339468\n",
      "Cost after iteration 1700: 0.336233\n",
      "Cost after iteration 1800: 0.341374\n",
      "Cost after iteration 1900: 0.336345\n",
      "Cost after iteration 2000: 0.338720\n",
      "Cost after iteration 2100: 0.331117\n",
      "Cost after iteration 2200: 0.329897\n",
      "Cost after iteration 2300: 0.330638\n",
      "Cost after iteration 2400: 0.330753\n",
      "Cost after iteration 2500: 0.328175\n",
      "Cost after iteration 2600: 0.326997\n",
      "Cost after iteration 2700: 0.327866\n",
      "Cost after iteration 2800: 0.320730\n",
      "Cost after iteration 2900: 0.324665\n",
      "Cost after iteration 3000: 0.326131\n",
      "Cost after iteration 3100: 0.317376\n",
      "Cost after iteration 3200: 0.320867\n",
      "Cost after iteration 3300: 0.318528\n",
      "Cost after iteration 3400: 0.319892\n",
      "Cost after iteration 3500: 0.321473\n",
      "Cost after iteration 3600: 0.311630\n",
      "Cost after iteration 3700: 0.312681\n",
      "Cost after iteration 3800: 0.310300\n",
      "Cost after iteration 3900: 0.310605\n",
      "Cost after iteration 4000: 0.310186\n",
      "Cost after iteration 4100: 0.320261\n",
      "Cost after iteration 4200: 0.309410\n",
      "Cost after iteration 4300: 0.307483\n",
      "Cost after iteration 4400: 0.314956\n",
      "Cost after iteration 4500: 0.310208\n",
      "Cost after iteration 4600: 0.301788\n",
      "Cost after iteration 4700: 0.310422\n",
      "Cost after iteration 4800: 0.305566\n",
      "Cost after iteration 4900: 0.297817\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(X_train.T, y_train.T, layers_dims = layers_dims, learning_rate = 0.0085,num_iterations = 5000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8808988764044945\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(X_train.T, y_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
