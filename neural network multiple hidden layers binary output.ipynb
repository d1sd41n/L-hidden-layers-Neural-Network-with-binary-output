{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "#from dnn_app_utils_v3 import *\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = W.dot(A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization. (â‰ˆ 1 line of code)\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 105\n",
      "Number of testing examples: m_test = 45\n",
      "number of features of each example: num_n = 4\n",
      "shape of x_train: (105, 4)\n",
      "shape of y_train: (105, 1)\n",
      "shape of x_test: (45, 4)\n",
      "shape of y_test: (45, 1)\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "# Iris dataset\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = ((iris.target != 0) * 1)  # convert the target's dataset into binary\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3)\n",
    "\n",
    "m_train = len(x_train)\n",
    "m_test = len(x_test)\n",
    "num_n = x_train.shape[1]\n",
    "numtest_n = x_test.shape[1]\n",
    "\n",
    "y_train = y_train.reshape(m_train,1)\n",
    "y_test = y_test.reshape(m_test,1)\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"number of features of each example: num_n = \" + str(num_n))\n",
    "print(\"shape of x_train:\",x_train.shape)\n",
    "print(\"shape of y_train:\",y_train.shape)\n",
    "print(\"shape of x_test:\",x_test.shape)\n",
    "print(\"shape of y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "### CONSTANTS ###\n",
    "layers_dims = [x_train.shape[1], 5, 1] #  4-layer model\n",
    "print(layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.256460\n",
      "Cost after iteration 100: 0.235538\n",
      "Cost after iteration 200: 0.221171\n",
      "Cost after iteration 300: 0.210490\n",
      "Cost after iteration 400: 0.201750\n",
      "Cost after iteration 500: 0.194182\n",
      "Cost after iteration 600: 0.187230\n",
      "Cost after iteration 700: 0.180763\n",
      "Cost after iteration 800: 0.174796\n",
      "Cost after iteration 900: 0.169202\n",
      "Cost after iteration 1000: 0.163901\n",
      "Cost after iteration 1100: 0.158811\n",
      "Cost after iteration 1200: 0.153920\n",
      "Cost after iteration 1300: 0.149220\n",
      "Cost after iteration 1400: 0.144706\n",
      "Cost after iteration 1500: 0.140382\n",
      "Cost after iteration 1600: 0.136228\n",
      "Cost after iteration 1700: 0.132242\n",
      "Cost after iteration 1800: 0.128529\n",
      "Cost after iteration 1900: 0.125027\n",
      "Cost after iteration 2000: 0.121709\n",
      "Cost after iteration 2100: 0.118551\n",
      "Cost after iteration 2200: 0.115517\n",
      "Cost after iteration 2300: 0.112594\n",
      "Cost after iteration 2400: 0.109778\n",
      "Cost after iteration 2500: 0.107069\n",
      "Cost after iteration 2600: 0.104463\n",
      "Cost after iteration 2700: 0.101968\n",
      "Cost after iteration 2800: 0.099571\n",
      "Cost after iteration 2900: 0.097261\n",
      "Cost after iteration 3000: 0.095036\n",
      "Cost after iteration 3100: 0.092892\n",
      "Cost after iteration 3200: 0.090823\n",
      "Cost after iteration 3300: 0.088825\n",
      "Cost after iteration 3400: 0.086896\n",
      "Cost after iteration 3500: 0.085034\n",
      "Cost after iteration 3600: 0.083233\n",
      "Cost after iteration 3700: 0.081490\n",
      "Cost after iteration 3800: 0.079806\n",
      "Cost after iteration 3900: 0.078175\n",
      "Cost after iteration 4000: 0.076596\n",
      "Cost after iteration 4100: 0.075067\n",
      "Cost after iteration 4200: 0.073586\n",
      "Cost after iteration 4300: 0.072150\n",
      "Cost after iteration 4400: 0.070758\n",
      "Cost after iteration 4500: 0.069409\n",
      "Cost after iteration 4600: 0.068100\n",
      "Cost after iteration 4700: 0.066831\n",
      "Cost after iteration 4800: 0.065599\n",
      "Cost after iteration 4900: 0.064403\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(x_train.T, y_train.T, layers_dims = layers_dims, learning_rate = 0.0005,num_iterations = 5000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(x_train.T, y_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(x_test.T, y_test.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 890\n",
      "number of features of each example: num_n = 4\n",
      "shape of x_train: (890, 17)\n",
      "shape of y_train: (890, 1)\n",
      "shape of x_test: (417, 17)\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "# Titanic Dataset\n",
    "\n",
    "X_train = pd.read_csv('./dataset/X_train.csv')\n",
    "y_train = pd.read_csv('./dataset/y_train.csv')\n",
    "X_test = pd.read_csv('./dataset/X_test.csv')\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "m_train = len(X_train)\n",
    "m_test = len(X_test)\n",
    "num_n = x_train.shape[1]\n",
    "numtest_n = x_test.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"number of features of each example: num_n = \" + str(num_n))\n",
    "print(\"shape of x_train:\",X_train.shape)\n",
    "print(\"shape of y_train:\",y_train.shape)\n",
    "print(\"shape of x_test:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 100, 50, 25, 10, 1]\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [17, 100, 50, 25, 10, 1]\n",
    "print(layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.768777\n",
      "Cost after iteration 100: 0.481226\n",
      "Cost after iteration 200: 0.447037\n",
      "Cost after iteration 300: 0.432118\n",
      "Cost after iteration 400: 0.422912\n",
      "Cost after iteration 500: 0.416226\n",
      "Cost after iteration 600: 0.410143\n",
      "Cost after iteration 700: 0.405434\n",
      "Cost after iteration 800: 0.401484\n",
      "Cost after iteration 900: 0.397959\n",
      "Cost after iteration 1000: 0.394901\n",
      "Cost after iteration 1100: 0.392011\n",
      "Cost after iteration 1200: 0.389372\n",
      "Cost after iteration 1300: 0.386949\n",
      "Cost after iteration 1400: 0.384706\n",
      "Cost after iteration 1500: 0.382593\n",
      "Cost after iteration 1600: 0.380547\n",
      "Cost after iteration 1700: 0.378565\n",
      "Cost after iteration 1800: 0.376628\n",
      "Cost after iteration 1900: 0.374744\n",
      "Cost after iteration 2000: 0.372970\n",
      "Cost after iteration 2100: 0.371265\n",
      "Cost after iteration 2200: 0.369608\n",
      "Cost after iteration 2300: 0.367981\n",
      "Cost after iteration 2400: 0.366276\n",
      "Cost after iteration 2500: 0.364720\n",
      "Cost after iteration 2600: 0.363303\n",
      "Cost after iteration 2700: 0.361939\n",
      "Cost after iteration 2800: 0.360590\n",
      "Cost after iteration 2900: 0.359246\n",
      "Cost after iteration 3000: 0.357963\n",
      "Cost after iteration 3100: 0.356712\n",
      "Cost after iteration 3200: 0.355259\n",
      "Cost after iteration 3300: 0.353956\n",
      "Cost after iteration 3400: 0.352704\n",
      "Cost after iteration 3500: 0.351501\n",
      "Cost after iteration 3600: 0.350296\n",
      "Cost after iteration 3700: 0.349113\n",
      "Cost after iteration 3800: 0.347873\n",
      "Cost after iteration 3900: 0.346701\n",
      "Cost after iteration 4000: 0.345554\n",
      "Cost after iteration 4100: 0.344378\n",
      "Cost after iteration 4200: 0.343208\n",
      "Cost after iteration 4300: 0.342033\n",
      "Cost after iteration 4400: 0.340882\n",
      "Cost after iteration 4500: 0.339660\n",
      "Cost after iteration 4600: 0.338474\n",
      "Cost after iteration 4700: 0.337326\n",
      "Cost after iteration 4800: 0.336275\n",
      "Cost after iteration 4900: 0.335068\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xuc3HV97/HXey+zm9ndbDbJ5n6HACo3AQGPlwNaPXgpVFELFQu1ldqWtgd7Odh61NrS47XWCtYroq2C1lsjUpEqXhCVBCRoIEAIgdyz2dz2kuxms5/zx+83k9nNbLJAZmd3f+/n4zGPmfnNd3/z/cFk3vP9fn+/71cRgZmZGUBNtStgZmbjh0PBzMyKHApmZlbkUDAzsyKHgpmZFTkUzMysyKFgk4Kk/5J0ZbXrYTbRORTsWZG0QdJvVLseEfGqiPhCtesBIOmHkv5gDN6nQdJNkvZJ2ibpHccof21abl/6dw0lry2RdJekXklrS/+fKvEPkjZL2pse3/NKXr9ZUr+k7pJbbWWO2irNoWDjnqS6atehYDzVBXgvsBxYDFwI/LWki8oVlPS/gOuAl6fllwF/V1LkFuCXwAzgb4GvSWpPX3sj8FbgJcB04GfAvw17iw9GRHPJ7dCzPzyrBoeCVYyk10p6QNIeSfdIOr3kteskPS6pS9JDkl5X8tpVkn4q6aOSOoH3ptvulvRhSbslPSHpVSV/U/x1PoqySyX9OH3v/5Z0o6R/H+EYLpC0SdL/kbQN+LykNkm3SepI93+bpAVp+etJvjxvSH8x35BuP0XSnZJ2SXpE0puOw3/iK4G/j4jdEfEw8BngqqOU/VxErImI3cDfF8pKOgk4C3hPROyPiK8DvwIuTf92KXB3RKxPv+z/HXjucai/jUMOBasISc8HbgL+kOTX56eAFSVdFo+TfHm2kvxi/XdJc0t2cR6wHpgNXF+y7RFgJvBB4HOSNEIVjlb2y8C9ab3eC7zlGIczh+QX8mLgapJ/N59Pny8C9gM3AETE3wI/Aa5JfzFfI6kJuDN931nAZcAnJJX9YpX0iTRIy90eTMu0AXOB1SV/uhp4Xrl9ptuHl50taUb62vqI6BphX7cCJ0g6SVI9ScB8d9j+/zgNvPskXYpNWA4Fq5SrgU9FxC8i4lDa398HnA8QEf8REVsiYjAivgI8Bpxb8vdbIuLjETEQEfvTbU9GxGfSX6tfIPlSnD3C+5ctK2kR8ALg3RHRHxF3AyuOcSyDJL+i+9Jf0p0R8fWI6E2/SK8H/udR/v61wIaI+Hx6PL8Evk7SLXOEiPjjiJg2wq3Q2mpO7/eW/OleoGWEOjSXKUtafvhrw/e1FbibJGT3p/W+tqTsv5B0Y80C/i9ws6QXjVAPG+ccClYpi4G/KP2VCywE5gFI+t2SrqU9wKkkv+oLNpbZ57bCg4joTR82lyl3tLLzgF0l20Z6r1IdEXGg8ERSXtKnJD0paR/wY2DaUQZXFwPnDftv8WaSFsgz1Z3eTy3ZNhXoKlO2UH54WdLyw18bvq93kwTpQqCRpGX3A0l5gIi4Pw3KgYi4HfgS8PqnfUQ2LjgUrFI2AtcP+5Wbj4hbJC0m6f++BpgREdOAXwOlXUGVmr53KzC98IWWWniMvxlel78ATgbOi4ipwEvT7Rqh/EbgR8P+WzRHxB+VezNJnxx2Jk/pbQ1AOi6wFTij5E/PANaMcAxrypTdHhGd6WvLJLUMe72wrzOBr0TEpvSL/2agjZHHFYKh/y9tAnEo2PFQL6mx5FZH8qX/dknnKdEk6TXpF08TyRdHB4Ck3yNpKVRcRDwJrCIZvM5JeiHwm09zNy0k3Sh7JE0H3jPs9e0kZ/cU3AacJOktkurT2wskPWeEOr592Jk8pbfSMYMvAu9KB75PAd4G3DxCnb8I/L6k50qaBryrUDYiHgUeAN6T/v97HXA6SRcXwErgjZJmS6qR9BagHlgHIOkNkprT114JXMGxu+RsnHIo2PFwO8mXZOH23ohYRfIldQOwm+QL5CqAiHgI+AjJqY3bgdOAn45hfd8MvBDoBP4B+ArJeMdo/TMwBdgJ/JwjB10/BrwhPTPpX9Jxh1eSDDBvIena+gDQwLPzHpIB+yeBHwEfiojvAkhalLYsFgGk2z8I3AU8lf5NaZhdBpxD8v/q/cAbIqIjfe0DJAPPDwB7SMYTLo2IPenrfw5sTl/7EPC2iPjhszw2qxJ5kR3LOklfAdZGxPBf/GaZ45aCZU7adXNC2t1xEXAJ8K1q18tsPBhPV2eajZU5wDdIrlPYBPxRepqoWea5+8jMzIrcfWRmZkUTrvto5syZsWTJkmpXw8xsQrnvvvt2RkT7scpNuFBYsmQJq1atqnY1zMwmFElPjqacu4/MzKzIoWBmZkUOBTMzK3IomJlZkUPBzMyKHApmZlbkUDAzs6LMhMLKDbv40B1rOTToaT3MzEaSmVB44Kk93HjX4/T2D1S7KmZm41ZmQiHfkCyf29t/qMo1MTMbvzITCk25ZEaPnj63FMzMRpKdUGgohIJbCmZmI8lOKOSS7qMejymYmY0oM6GQT1sKHmg2MxtZZkKh2FJw95GZ2YgyEwpuKZiZHVtmQsEtBTOzY8tMKORzbimYmR1LZkIhV1dDrraGHl+8ZmY2osyEAiRXNfviNTOzkWUqFJpydR5TMDM7ikyFQj5X6zEFM7OjyFYoNNR5TMHM7CgyFQpNuVp6PaZgZjaiTIVCPueWgpnZ0WQqFJoaPKZgZnY0GQuFOp+SamZ2FNkKhVytT0k1MzuKTIVCPlfH/oOHODQY1a6Kmdm4lKlQaErXad5/0K0FM7NyMhUKxUnxPK5gZlZWpkKh0FLwaalmZuVlKhQKLQWfgWRmVl6mQqGpuKaCWwpmZuVkKxQK3UduKZiZlZWxUEi7j3xVs5lZWRUNBUkXSXpE0jpJ15V5/aOSHkhvj0raU8n65NN1mnt9AZuZWVl1ldqxpFrgRuAVwCZgpaQVEfFQoUxEXFtS/k+B51eqPnB4TMEtBTOz8irZUjgXWBcR6yOiH7gVuOQo5S8HbqlgfcinYwoeaDYzK6+SoTAf2FjyfFO67QiSFgNLgR9UsD7kamuoq5EHms3MRjBeBpovA74WEWV/wku6WtIqSas6Ojqe8ZtISpfkdEvBzKycSobCZmBhyfMF6bZyLuMoXUcR8emIOCcizmlvb39WlWr29NlmZiOqZCisBJZLWiopR/LFv2J4IUmnAG3AzypYl6JknWaHgplZORULhYgYAK4B7gAeBr4aEWskvU/SxSVFLwNujYgxmc/aayqYmY2sYqekAkTE7cDtw7a9e9jz91ayDsPlc3VektPMbATjZaB5zDQ1uKVgZjaSzIWCWwpmZiPLXCg0NdR6PQUzsxFkLhTyuTqvvGZmNoLMhUJTQx29Bw8xODgmJzuZmU0o2QuFXC0RsP+gu5DMzIbLXCjkvaaCmdmIMhcKTV5TwcxsRJkLhbzXVDAzG1HmQqHJayqYmY0oc6FQbCn4tFQzsyNkLhSa04FmtxTMzI6UuVDIpwPNbimYmR0pc6HQ1ODuIzOzkWQuFIotBXcfmZkdIXOh0FBXQ22NPFOqmVkZmQsFSeS9+pqZWVmZCwWAJq+pYGZWViZDIe81FczMyspkKDQ3eE0FM7NyMhkK+ZxbCmZm5WQyFJpydb5OwcysjEyGQr6hztNcmJmVkclQaMrVuqVgZlZGJkMhn3NLwcysnEyGQlNDLT39A0REtatiZjauZDIU8rk6IuDAwcFqV8XMbFzJZCg0NxQmxfO4gplZqUyGgldfMzMrL5OhUFin2ZPimZkNlclQKLQUPCmemdlQmQyFYkvBp6WamQ2RyVAothQ8pmBmNkQmQ6GpMNDsloKZ2RDZDIW0+8hjCmZmQ2U0FAqnpLqlYGZWKpOh0FBXQ418nYKZ2XAVDQVJF0l6RNI6SdeNUOZNkh6StEbSlytZn5L3TNZUcPeRmdkQdZXasaRa4EbgFcAmYKWkFRHxUEmZ5cA7gRdFxG5JsypVn+HyDbX0uvvIzGyISrYUzgXWRcT6iOgHbgUuGVbmbcCNEbEbICJ2VLA+Q7ilYGZ2pEqGwnxgY8nzTem2UicBJ0n6qaSfS7qo3I4kXS1plaRVHR0dx6Vy+YZar6lgZjZMtQea64DlwAXA5cBnJE0bXigiPh0R50TEOe3t7cfljfNep9nM7AiVDIXNwMKS5wvSbaU2ASsi4mBEPAE8ShISFdfsdZrNzI5QyVBYCSyXtFRSDrgMWDGszLdIWglImknSnbS+gnUqyudqPaZgZjZMxUIhIgaAa4A7gIeBr0bEGknvk3RxWuwOoFPSQ8BdwF9FRGel6lSqyd1HZmZHqNgpqQARcTtw+7Bt7y55HMA70tuY8impZmZHqvZAc9UUTklNcsnMzCDDoZBvqGUwoG9gsNpVMTMbNzIbCk1ep9nM7AjZDYWGwpKcHlcwMyvIbijkCktyuqVgZlaQ2VDIe00FM7MjZDYUii0FjymYmRVlNhTyucKYgkPBzKxgVKEg6Y2j2TaRFNZpdveRmdlho20pvHOU2yYMtxTMzI501GkuJL0KeDUwX9K/lLw0FZjQ36bFloJPSTUzKzrW3EdbgFXAxcB9Jdu7gGsrVamxMKW+Fgl6PdBsZlZ01FCIiNXAaklfjoiDAJLagIWFJTQnKknp/EduKZiZFYx2TOFOSVMlTQfuJ1kh7aMVrNeYyOdqPaZgZlZitKHQGhH7gNcDX4yI84CXV65aY6OpoY5un31kZlY02lCokzQXeBNwWwXrM6byuVqPKZiZlRhtKLyPZJW0xyNipaRlwGOVq9bYKKypYGZmiVGtvBYR/wH8R8nz9cCllarUWMk31LKrp7/a1TAzGzdGe0XzAknflLQjvX1d0oJKV67SvE6zmdlQo+0++jywApiX3r6dbpvQmhpqvZ6CmVmJ0YZCe0R8PiIG0tvNQHsF6zUm8m4pmJkNMdpQ6JR0haTa9HYF0FnJio2FQkshIqpdFTOzcWG0ofBWktNRtwFbgTcAV1WoTmMmn6tjYDDoGxisdlXMzMaFUZ19RHJK6pWFqS3SK5s/TBIWE1ZhoZ3e/kM01tdWuTZmZtU32pbC6aVzHUXELuD5lanS2Dm8JKfHFczMYPShUJNOhAcUWwqjbWWMW03FNRV8BpKZGYz+i/0jwM8kFS5geyNwfWWqNHYOr6ngloKZGYz+iuYvSloFvCzd9PqIeKhy1RobTWn3Ua8nxTMzA55GF1AaAhM+CErlc24pmJmVGu2YwqTU5HWazcyGyHQo5NMxBa+pYGaWyHQoFFsKPiXVzAzIeChMqS+MKbilYGYGGQ+Fmhp59TUzsxKZDgVITkt1S8HMLOFQyNX67CMzs1TmQyFZU8EtBTMzqHAoSLpI0iOS1km6rszrV0nqkPRAevuDStannKaGWk+IZ2aWqtikdpJqgRuBVwCbgJWSVpSZHuMrEXFNpepxLPlcHXt6+6v19mZm40olWwrnAusiYn1E9AO3ApdU8P2ekaaGWg80m5mlKhkK84GNJc83pduGu1TSg5K+JmlhuR1JulrSKkmrOjo6jmsl87k6n5JqZpaq9kDzt4ElEXE6cCfwhXKFIuLTEXFORJzT3t5+XCvQ7FNSzcyKKhkKm4HSX/4L0m1FEdEZEX3p088CZ1ewPmXlfUqqmVlRJUNhJbBc0lJJOeAyYEVpAUlzS55eDDxcwfqU1dRQx8FDQf/A4Fi/tZnZuFOxs48iYkDSNcAdQC1wU0SskfQ+YFVErAD+TNLFwACwC7iqUvUZSWFNhd7+AXJ1ubF+ezOzcaWi6yxHxO3A7cO2vbvk8TuBd1ayDsdSmCm1u2+AaXmHgpllW7UHmquusKZCrwebzcwcCoWWgq9qNjNzKDBragMAa7d1VbkmZmbVl/lQeO7cqZw8u4VbV248dmEzs0ku86EgicvPXcjqjXtYs2VvtatjZlZVmQ8FgNc9fwENdTXceq9bC2aWbQ4FoDVfz2tOn8u3frnZVzebWaY5FFK/c+4iuvoGuG311mpXxcysahwKqbMXt7F8VjNfvvepalfFzKxqHAqpZMB5EQ9s3MNDW/ZVuzpmZlXhUCjx+rPmk6ur4daVbi2YWTY5FEpMy+d4zWlz+eb9m9nvaS/MLIMcCsNcXhhwfnBLtatiZjbmHArDvGBJGye0N3GLB5zNLIMcCsMUBpzvf2oPa7d5wNnMssWhUMalZy0gV+srnM0sexwKZbQ15XjVaXP4xv2bPOBsZpniUBjB5ecuYt+BAb70iyerXRUzszHjUBjBeUunc8HJ7fzj7Q9zx5pt1a6OmdmYcCiMQBKfePNZnL5gGn96yy/5xfrOalfJzKziHApHkc/V8fmrXsCi6Xn+4AurPP2FmU16DoVjaGvK8cW3nktzYx1Xfv5enursrXaVzMwqxqEwCvOmTeGLbz2Xg4cGectNv6Cjq6/aVTIzqwiHwigtn93CTVe9gB37+rjypnvZd+BgtatkZnbcORSehrMWtfGvV5zFo9u7eNMnf+YxBjObdBwKT9MFJ8/iM1eew87ufi658W4+/v3HGDg0WO1qmZkdFw6FZ+DCk2dx57Uv5aJT5/KROx/l9f96D49t76p2tczMnjWHwjPU1pTj45c/n0+8+Sw27d7Paz5+N5/60eMcGoxqV83M7BlzKDxLrz5tLt+79qVceHI7/++/1vK6T/yUu9buIMLhYGYTj0PhOJjZ3MAnrzibj112Jp3d/fzezSu5+Iaf8r012xwOZjahaKJ9aZ1zzjmxatWqaldjRAcPDfLN+zdzw13reGpXL6fMaeHPXr6ci543h5oaVbt6ZpZRku6LiHOOWc6hUBkDhwZZsXoLN/xgHet39nDirGbe9pKlXHLmfBrra6tdPTPLGIfCOHFoMPjOr7byibvWsXZbFzObc7zl/CVccf4iZjQ3VLt6ZpYRDoVxJiK45/FOPvuT9dz1SAcNdTW8/qz5/P6Ll3LirJZqV8/MJrnRhkLdWFTGkqm4X3TiTF504kzW7ejic3c/wdfv38wt927krEXT+M0z5vGa0+cyq6Wx2lU1swxzS6GKdnb38dVVG1nxwBbWbuuiRnD+shlcfMY8Ljp1DtPyuWpX0cwmiXHRfSTpIuBjQC3w2Yh4/wjlLgW+BrwgIo76jT+ZQqHUY9u7+PbqLaxYvYUNnb3U14rzl83ggpNnceHJ7Syd2YTks5fM7JmpeihIqgUeBV4BbAJWApdHxEPDyrUA3wFywDVZDYWCiGDNln18e/UWvr92B+t2dAOweEaeC0+exYWnzOK8pdN9BpOZPS3jYUzhXGBdRKxPK3QrcAnw0LByfw98APirCtZlwpDEqfNbOXV+K+989XPYuKuXHz6ygx+s3cEt9z7FzfdsIFdXwzmL2/gfJ8zghSfM5PQFrdTX+jpEM3v2KhkK84GNJc83AeeVFpB0FrAwIr4jacRQkHQ1cDXAokWLKlDV8Wvh9DxveeES3vLCJRw4eIifPd7J3et2cs/jnXz4e48Cj9LcUMe5S6dz/rLpnL24jefNa3VLwsyekaqdfSSpBvgn4KpjlY2ITwOfhqT7qLI1G78a62u58JSkCwlgV08/P1/fyT2PJyHxg7U7AMjV1vC8+VM5e1EbZy1u46xFbcxp9VlNZnZslQyFzcDCkucL0m0FLcCpwA/TAdQ5wApJFx9rXMES05tyvPq0ubz6tLkAdHT1cf9Tu5Pbk7v5t58/yWfvfgKAOVMbOWNhK2cubOOMha2cNr+Vlsb6albfzMahSg4015EMNL+cJAxWAr8TEWtGKP9D4C+zPtB8PPUPDPLQ1n3c/+RuVm/aw+qNe9jQ2QuABCe2N3Pa/FaeO28qp6b3Ux0UZpNS1QeaI2JA0jXAHSSnpN4UEWskvQ9YFRErKvXelsjV1XDmwmmcuXBacdvunv40IPayetMe7l63k2/88nADbvGMPKfOa+U5c1s4Zc5UTp7TwoK2KT4d1iwjfPGasaPrAGu27OOhLfv49ea9rNmyj6d29RZfb2mo46Q5LZwyp4WT57SwfFYLy2c3M6Mp57AwmyCqfp1CpTgUxkZ33wCPbOvikW1drN22j7Xbuli7dR/7DgwUy7Tl61k+q4UTZzdzYnszJ8xq5oT2Jua1TvE04WbjTNW7j2xia26o4+zFbZy9uK24LSLY0dXHo9u7eGx7N4/t6Gbdji6+8+BW9u4/WCzXWF/DsplJSCyb2cSy9iaWzWxmaXsTzQ3+yJmNZ/4XaqMmidlTG5k9tZGXLG8vbo8IOrr7WN/Rw/qOHh7v6GZ9RzerN+7htge3UNoYndXSwNI0KJbObGLJjOR+0Yw8DXW+tsKs2hwK9qxJYlZLI7NaGjl/2Ywhrx04eIindvUmgbGzmyc6eli/s4fv/nobu3sPluwD5rVOYVl7EhSLZ+RZMqOJJTObWDh9igPDbIw4FKyiGutrOWl2CyfNPnLNiL29B3mis4cNO5Og2LCzhyd29vCtjZvpKhm7qBHMmzaFJTOSFsWSGXkWTW9iycw8i6bnyef8MTY7XvyvyaqmNV/Pmfmhp8xC0h21u/cgT+zs4cnOHjZ09rIhfXz7r7ayp6SFAdDe0sCi6XkWtk1h4fR8cmvLs3D6FOa2TqHWg95mo+ZQsHFHEtObckxvyg0Z6C7Y23uQJ3f18GRnL092Jvcbd/eycsNuVqzewmDJGEZdjZg7rZEF0/IsaJvCgrbkfn7bFOZPm8Lc1kbqPJmgWZFDwSac1nw9p+encfqCaUe8dvDQIFv27Gfjrv1s3N3Lpt29bNq9n0279/PjxzrYvq9vSPkaJVOAFEIiuc+n943MmzbF3VOWKf6026RSX1vD4hlNLJ7RVPb1AwcPsWXPfjbv2c/m3YfvN+3Zz8oNu/n2g1s5NDj02p22fH2xhVHa2ljQloSHT7O1ycSfZsuUxvpalrU3s6y9uezrA4cG2dHVx+Y9+9myJ2lhFO4f29HNXY/s4MDBwSF/M7WxjnlpV9TcaVOY19rI3Nbk+aypjcxpbXRw2IThT6pZibraGuZNm8K8aVPKvh4R7OzuH9IttXXvfrbsOcDWvftZvWkvu3r6j/i7plwts1sbmd2ShMSslgZmTU3uk2s/GpjV0siUnE+9tepyKJg9DZJob2mgvaWB5y86chAcYH//Ibbu3c/2fX1s33eA7fsOsK1wv/cAKzfsYkdXH/0Dg0f8bUtDHbPSgJg99XBwtKfhUQgTtzysUvzJMjvOpuSO3kUFSYtj7/6DbN/Xx46uA8X7HSXP73tqN9v3lQ+PfK42CYiWxmJItbc00N58+PHM5gZmNOe8VKs9LQ4FsyqQxLR8jmn5HCfPOfLCvoKIYN/+gSQwupKWx46uPnbs62N71wF2dvXx8LZ9/PixviEX/JVqy9cXQ6IwTcnc1uR+TmvyeGZzg6/nMMChYDauSaI1X09rvp7lZa4KL3Xg4CE6uvrY0dXHzu7k1tF1+L6jq497n9jFjq4DHDw09AyrGsGM5qSlMWvq0PuZJS2QmS0NtDTUecr0ScyhYDZJNNbXFq/oPprBwWBXbz/b9iZjHFv3HaAjbYEUQmXt1i52dvcxMHjk1PoNdTXMTMNiZlOu2E1VuC8EyYymHG35nKdRn2AcCmYZU1Oj5Eu9uYFT57eOWG5wMNjd28/O7v4hLY7ifU8/W/ce4Feb99LZ03/E9R0AtTXJ1ekzmnK0p0GRhEchSHLMaEpaITOac574cBxwKJhZWTU1Sr+8G4467gFJgOzdfzDttupnZ3cfnenjzp4+OrqS+yc7e9nZ3Udv/6Gy+5naWJe0QNKurJnNuWKAzGga+tzdWJXhUDCzZ62mRrQ15WhryrF89rHL9/YP0NndT2fP4VbIzkIrpLuPnV39PLx1Hzu7+4as9leqvlbMaGpIWiKF7qum3BGtkMJrjfVuhYyGQ8HMxlw+V0d+et0xxz8A+gcG2dWTtj56+tnZ1ceuniRQOrsPP97Q2UNnd/+IrZCmXG2ZVsfQ4Cg8n96Uy+zZWA4FMxvXcnU1zGlNTp8djdJWSGd3X7FLq7O7n109SbBs3rOfBzftGXEsRIK2fK44HjKz+XCLJDlLK1ccl5nZ0kBTrnbSdGU5FMxsUnk6rZDBwWDfgYNpaPQVg6SjECBpmKzdto/Onv4j1vIomFJfOyQwCq2PGYVxkbT1MbM56WIbzxcUOhTMLLNqag5fRHjirJGvQC84eCjpyiqOg3Qfbo10dvfT0d3Hlj3pGVnd/WVP6QVonVKfnLKbnrbblq9nevp8ej43JFDGejzEoWBmNkr1tTXFq8KPpTCVSdL6KG2JJK2QnT397OlNurJ+vXkvu3r7y05pAtDcUMfM5hzveOXJXHzGvON9WEM4FMzMKqB0KpMT2o9dPiLYf/BQcTykcDZW6Rla0/O5itfboWBmNg5IelrjIZUyfkc7zMxszDkUzMysyKFgZmZFDgUzMytyKJiZWZFDwczMihwKZmZW5FAwM7MiRZSfm2O8ktQBPPkM/3wmsPM4VmeiyOpxQ3aP3cedLaM57sURccxrqydcKDwbklZFxDnVrsdYy+pxQ3aP3cedLcfzuN19ZGZmRQ4FMzMryloofLraFaiSrB43ZPfYfdzZctyOO1NjCmZmdnRZaymYmdlROBTMzKwoM6Eg6SJJj0haJ+m6atenUiTdJGmHpF+XbJsu6U5Jj6X3bdWsYyVIWijpLkkPSVoj6c/T7ZP62CU1SrpX0ur0uP8u3b5U0i/Sz/tXJFV+ya4qkFQr6ZeSbkufT/rjlrRB0q8kPSBpVbrtuH3OMxEKkmqBG4FXAc8FLpf03OrWqmJuBi4atu064PsRsRz4fvp8shkA/iIingucD/xJ+v94sh97H/CyiDgDOBO4SNL5wAeAj0bEicBu4PerWMdK+nPg4ZLnWTnuCyPizJJrE47b5zwToQCcC6yLiPUR0Q/cClxS5TpVRET8GNg1bPMlwBfSx18AfmtMKzUGImJrRNyfPu4i+aKYzyQ/9kh0p0/r01sALwO+lm6fdMcNIGkB8Brgs+lzkYHjHsFx+5xnJRTmAxtLnm9Kt2XF7IjYmj7eBsyuZmUqTdIS4PnAL8jAsaddKA8AO4D5ZD31AAAFtUlEQVQ7gceBPRExkBaZrJ/3fwb+GhhMn88gG8cdwPck3Sfp6nTbcfuc1z3b2tnEEhEhadKehyypGfg68L8jYl/y4zExWY89Ig4BZ0qaBnwTOKXKVao4Sa8FdkTEfZIuqHZ9xtiLI2KzpFnAnZLWlr74bD/nWWkpbAYWljxfkG7Liu2S5gKk9zuqXJ+KkFRPEghfiohvpJszcewAEbEHuAt4ITBNUuFH32T8vL8IuFjSBpLu4JcBH2PyHzcRsTm930HyI+BcjuPnPCuhsBJYnp6ZkAMuA1ZUuU5jaQVwZfr4SuA/q1iXikj7kz8HPBwR/1Ty0qQ+dkntaQsBSVOAV5CMp9wFvCEtNumOOyLeGRELImIJyb/nH0TEm5nkxy2pSVJL4THwSuDXHMfPeWauaJb0apI+yFrgpoi4vspVqghJtwAXkEylux14D/At4KvAIpJpx98UEcMHoyc0SS8GfgL8isN9zH9DMq4waY9d0ukkA4u1JD/yvhoR75O0jOQX9HTgl8AVEdFXvZpWTtp99JcR8drJftzp8X0zfVoHfDkirpc0g+P0Oc9MKJiZ2bFlpfvIzMxGwaFgZmZFDgUzMytyKJiZWZFDwczMihwKNm5Iuie9XyLpd47zvv+m3HtViqTfkvTuCu37b45d6mnv8zRJNx/v/drE41NSbdwpPe/8afxNXcmcN+Ve746I5uNRv1HW5x7g4ojY+Sz3c8RxVepYJP038NaIeOp479smDrcUbNyQVJjt8/3AS9L54q9NJ3z7kKSVkh6U9Idp+Qsk/UTSCuChdNu30onC1hQmC5P0fmBKur8vlb6XEh+S9Ot0jvrfLtn3DyV9TdJaSV9Kr5pG0vuVrNvwoKQPlzmOk4C+QiBIulnSJyWtkvRoOm9PYSK7UR1Xyb7LHcsVStZUeEDSp9Kp4pHULel6JWst/FzS7HT7G9PjXS3pxyW7/zbJ1cGWZRHhm2/j4gZ0p/cXALeVbL8aeFf6uAFYBSxNy/UAS0vKTk/vp5Bc/j+jdN9l3utSkplFa0lmlnwKmJvuey/J/Dk1wM+AF5PMxPkIh1vZ08ocx+8BHyl5fjPw3XQ/y0lm72x8OsdVru7p4+eQfJnXp88/Afxu+jiA30wff7DkvX4FzB9ef5L5hL5d7c+Bb9W9eZZUmwheCZwuqTCnTSvJl2s/cG9EPFFS9s8kvS59vDAt13mUfb8YuCWSmUa3S/oR8AJgX7rvTQBKpqZeAvwcOAB8TslqX7eV2edcoGPYtq9GxCDwmKT1JDOZPp3jGsnLgbOBlWlDZgqHJ0PrL6nffSTzIgH8FLhZ0leBbxzeFTuAeaN4T5vEHAo2EQj404i4Y8jGZOyhZ9jz3wBeGBG9kn5I8ov8mSqdM+cQUBcRA5LOJfkyfgNwDckMnaX2k3zBlxo+eBeM8riOQcAXIuKdZV47GBGF9z1E+u89It4u6TySBWruk3R2RHSS/LfaP8r3tUnKYwo2HnUBLSXP7wD+SMnU2Eg6KZ0hcrhWYHcaCKeQLMtZcLDw98P8BPjttH+/HXgpcO9IFVOyXkNrRNwOXAucUabYw8CJw7a9UVKNpBOAZSRdUKM9ruFKj+X7wBuUzK1fWKt38dH+WNIJEfGLiHg3SYumMK38SSRdbpZhbinYePQgcEjSapL++I+RdN3cnw72dlB+ucHvAm+X9DDJl+7PS177NPCgpPsjmWK54Jsk6w+sJvn1/tcRsS0NlXJagP+U1EjyK/0dZcr8GPiIJJX8Un+KJGymAm+PiAOSPjvK4xpuyLFIehfJSlw1wEHgT0hmyhzJhyQtT+v//fTYAS4EvjOK97dJzKekmlWApI+RDNr+d3r+/20R8bVj/FnVSGoAfkSyqteIp/ba5OfuI7PK+EcgX+1KPA2LgOscCOaWgpmZFbmlYGZmRQ4FMzMrciiYmVmRQ8HMzIocCmZmVvT/AYCMpGFCOeBVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(X_train.T, y_train.T, layers_dims = layers_dims, learning_rate = 0.0085,num_iterations = 5000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8629213483146069\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(X_train.T, y_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
