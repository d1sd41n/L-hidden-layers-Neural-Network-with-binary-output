{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "#from dnn_app_utils_v3 import *\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    W1 = np.random.randn(n_h, n_x)*0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h)*0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = W.dot(A) + b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)\n",
    "    db = 1./m * np.sum(dZ, axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization. (â‰ˆ 1 line of code)\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        \n",
    "        # Compute cost.\n",
    "        cost = compute_cost(AL, Y)\n",
    "    \n",
    "        # Backward propagation.\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    " \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate=learning_rate)\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 105\n",
      "Number of testing examples: m_test = 45\n",
      "number of features of each example: num_n = 4\n",
      "shape of x_train: (105, 4)\n",
      "shape of y_train: (105, 1)\n",
      "shape of x_test: (45, 4)\n",
      "shape of y_test: (45, 1)\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "# Iris dataset\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data\n",
    "y = ((iris.target != 0) * 1)  # convert the target's dataset into binary\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.3)\n",
    "\n",
    "m_train = len(x_train)\n",
    "m_test = len(x_test)\n",
    "num_n = x_train.shape[1]\n",
    "numtest_n = x_test.shape[1]\n",
    "\n",
    "y_train = y_train.reshape(m_train,1)\n",
    "y_test = y_test.reshape(m_test,1)\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"number of features of each example: num_n = \" + str(num_n))\n",
    "print(\"shape of x_train:\",x_train.shape)\n",
    "print(\"shape of y_train:\",y_train.shape)\n",
    "print(\"shape of x_test:\",x_test.shape)\n",
    "print(\"shape of y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "### CONSTANTS ###\n",
    "layers_dims = [x_train.shape[1], 5, 1] #  4-layer model\n",
    "print(layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.254515\n",
      "Cost after iteration 100: 0.235019\n",
      "Cost after iteration 200: 0.220759\n",
      "Cost after iteration 300: 0.210022\n",
      "Cost after iteration 400: 0.201175\n",
      "Cost after iteration 500: 0.193459\n",
      "Cost after iteration 600: 0.186347\n",
      "Cost after iteration 700: 0.179704\n",
      "Cost after iteration 800: 0.173433\n",
      "Cost after iteration 900: 0.167592\n",
      "Cost after iteration 1000: 0.162064\n",
      "Cost after iteration 1100: 0.156836\n",
      "Cost after iteration 1200: 0.151845\n",
      "Cost after iteration 1300: 0.147110\n",
      "Cost after iteration 1400: 0.142586\n",
      "Cost after iteration 1500: 0.138248\n",
      "Cost after iteration 1600: 0.134087\n",
      "Cost after iteration 1700: 0.130113\n",
      "Cost after iteration 1800: 0.126313\n",
      "Cost after iteration 1900: 0.122748\n",
      "Cost after iteration 2000: 0.119374\n",
      "Cost after iteration 2100: 0.116163\n",
      "Cost after iteration 2200: 0.113113\n",
      "Cost after iteration 2300: 0.110188\n",
      "Cost after iteration 2400: 0.107375\n",
      "Cost after iteration 2500: 0.104674\n",
      "Cost after iteration 2600: 0.102082\n",
      "Cost after iteration 2700: 0.099587\n",
      "Cost after iteration 2800: 0.097193\n",
      "Cost after iteration 2900: 0.094893\n",
      "Cost after iteration 3000: 0.092683\n",
      "Cost after iteration 3100: 0.090559\n",
      "Cost after iteration 3200: 0.088511\n",
      "Cost after iteration 3300: 0.086535\n",
      "Cost after iteration 3400: 0.084629\n",
      "Cost after iteration 3500: 0.082789\n",
      "Cost after iteration 3600: 0.081010\n",
      "Cost after iteration 3700: 0.079290\n",
      "Cost after iteration 3800: 0.077630\n",
      "Cost after iteration 3900: 0.076026\n",
      "Cost after iteration 4000: 0.074475\n",
      "Cost after iteration 4100: 0.072975\n",
      "Cost after iteration 4200: 0.071522\n",
      "Cost after iteration 4300: 0.070115\n",
      "Cost after iteration 4400: 0.068751\n",
      "Cost after iteration 4500: 0.067430\n",
      "Cost after iteration 4600: 0.066150\n",
      "Cost after iteration 4700: 0.064908\n",
      "Cost after iteration 4800: 0.063704\n",
      "Cost after iteration 4900: 0.062536\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(x_train.T, y_train.T, layers_dims = layers_dims, learning_rate = 0.0005,num_iterations = 5000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(x_train.T, y_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(x_test.T, y_test.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 890\n",
      "number of features of each example: num_n = 4\n",
      "shape of x_train: (890, 17)\n",
      "shape of y_train: (890, 1)\n",
      "shape of x_test: (417, 17)\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "# Titanic Dataset\n",
    "\n",
    "X_train = pd.read_csv('./dataset/X_train.csv')\n",
    "y_train = pd.read_csv('./dataset/y_train.csv')\n",
    "X_test = pd.read_csv('./dataset/X_test.csv')\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test = X_test.values\n",
    "\n",
    "m_train = len(X_train)\n",
    "m_test = len(X_test)\n",
    "num_n = x_train.shape[1]\n",
    "numtest_n = x_test.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"number of features of each example: num_n = \" + str(num_n))\n",
    "print(\"shape of x_train:\",X_train.shape)\n",
    "print(\"shape of y_train:\",y_train.shape)\n",
    "print(\"shape of x_test:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 100, 50, 25, 10, 1]\n"
     ]
    }
   ],
   "source": [
    "layers_dims = [17, 100, 50, 25, 10, 1]\n",
    "print(layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.768777\n",
      "Cost after iteration 100: 0.481226\n",
      "Cost after iteration 200: 0.447037\n",
      "Cost after iteration 300: 0.432118\n",
      "Cost after iteration 400: 0.422912\n",
      "Cost after iteration 500: 0.416226\n",
      "Cost after iteration 600: 0.410143\n",
      "Cost after iteration 700: 0.405434\n",
      "Cost after iteration 800: 0.401484\n",
      "Cost after iteration 900: 0.397959\n",
      "Cost after iteration 1000: 0.394901\n",
      "Cost after iteration 1100: 0.392011\n",
      "Cost after iteration 1200: 0.389372\n",
      "Cost after iteration 1300: 0.386949\n",
      "Cost after iteration 1400: 0.384706\n",
      "Cost after iteration 1500: 0.382593\n",
      "Cost after iteration 1600: 0.380547\n",
      "Cost after iteration 1700: 0.378565\n",
      "Cost after iteration 1800: 0.376628\n",
      "Cost after iteration 1900: 0.374744\n",
      "Cost after iteration 2000: 0.372970\n",
      "Cost after iteration 2100: 0.371265\n",
      "Cost after iteration 2200: 0.369608\n",
      "Cost after iteration 2300: 0.367981\n",
      "Cost after iteration 2400: 0.366276\n",
      "Cost after iteration 2500: 0.364720\n",
      "Cost after iteration 2600: 0.363303\n",
      "Cost after iteration 2700: 0.361939\n",
      "Cost after iteration 2800: 0.360590\n",
      "Cost after iteration 2900: 0.359246\n",
      "Cost after iteration 3000: 0.357963\n",
      "Cost after iteration 3100: 0.356712\n",
      "Cost after iteration 3200: 0.355259\n",
      "Cost after iteration 3300: 0.353956\n",
      "Cost after iteration 3400: 0.352704\n",
      "Cost after iteration 3500: 0.351501\n",
      "Cost after iteration 3600: 0.350296\n",
      "Cost after iteration 3700: 0.349113\n",
      "Cost after iteration 3800: 0.347873\n",
      "Cost after iteration 3900: 0.346701\n",
      "Cost after iteration 4000: 0.345554\n",
      "Cost after iteration 4100: 0.344378\n",
      "Cost after iteration 4200: 0.343208\n",
      "Cost after iteration 4300: 0.342033\n",
      "Cost after iteration 4400: 0.340882\n",
      "Cost after iteration 4500: 0.339660\n",
      "Cost after iteration 4600: 0.338474\n",
      "Cost after iteration 4700: 0.337326\n",
      "Cost after iteration 4800: 0.336275\n",
      "Cost after iteration 4900: 0.335068\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(X_train.T, y_train.T, layers_dims = layers_dims, learning_rate = 0.0085,num_iterations = 5000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8629213483146069\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(X_train.T, y_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
